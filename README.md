# ğŸš€ Next Word Predictor using LSTM
https://colab.research.google.com/drive/1PVXHaBerGX5W608ps-LoyUN1DL_-5epj?usp=sharing

## ğŸ“Œ Project Overview
This mini project demonstrates the implementation of a **Next Word Prediction** model using **Long Short-Term Memory (LSTM)** networks.  
The model learns from a text corpus and predicts the most likely word that follows a given sequence.  

This project was built to **understand and practice LSTM implementation in NLP** and showcases how deep learning can be applied in predictive text applications like autocomplete systems.

---

## ğŸ¯ Objectives
- Learn the basics of text preprocessing and tokenization.
- Implement a sequential model using **LSTMs** for text prediction.
- Train and evaluate the model using a custom dataset.
- Demonstrate the use of embeddings and recurrent neural networks in NLP tasks.

---

## ğŸ› ï¸ Tech Stack
- **Programming Language:** Python  
- **Libraries & Frameworks:** TensorFlow, Keras, NumPy, Pandas, NLTK, Matplotlib  

---



## ğŸ”‘ Features
- Text preprocessing: lowercasing, punctuation removal, tokenization.
- Sequence generation for model training.
- LSTM-based architecture with embedding layer.
- Predicts the **next word** given an input phrase.
- Generates **Top-N probable predictions** using softmax probabilities.

---

## âš™ï¸ How It Works
1. **Prepare the dataset** â†’ Clean and tokenize the text corpus.  
2. **Generate sequences** â†’ Convert sentences into (X, y) pairs for training.  
3. **Build the model** â†’ Embedding layer â†’ LSTM layers â†’ Dense + Softmax.  
4. **Train the model** â†’ Optimize using categorical cross-entropy and Adam optimizer.  
5. **Make predictions** â†’ Input a phrase, and the model predicts the next word.  

---

## ğŸ“Š Results & Applications
- Successfully predicts context-aware next words.  
- Applications:  
  - Autocomplete in search engines & messaging apps  
  - Smart assistants (Google Assistant, Alexa, Siri)  
  - Code autocompletion systems  

---

## ğŸš€ Future Improvements
- Use **pre-trained embeddings** (Word2Vec, GloVe, FastText).  
- Experiment with **Bidirectional LSTMs** and **GRUs**.  
- Extend to **Transformer-based models** (GPT, BERT).  
- Deploy as a simple web app using Flask/Django.  

---

## ğŸ“… Project Timeline
- **Duration:** May 2025 â€“ June 2025  
- **Type:** Mini Project (for learning LSTM implementation in NLP)


images 
<img width="705" height="809" alt="Screenshot 2025-10-04 171521" src="https://github.com/user-attachments/assets/59db866c-890e-4ad2-bf90-9ee1ca714949" />
<img width="716" height="646" alt="Screenshot 2025-10-04 171943" src="https://github.com/user-attachments/assets/0464681e-10eb-4215-961f-3620b8686664" />
<img width="747" height="765" alt="Screenshot 2025-10-04 171748" src="https://github.com/user-attachments/assets/88e6095c-700d-44a6-9f87-5d0b46a12f1e" />
<img width="835" height="801" alt="Screenshot 2025-10-04 173820" src="https://github.com/user-attachments/assets/1452c78e-003d-42db-a10d-dbc5a21138d5" />
<img width="756" height="698" alt="Screenshot 2025-10-04 173713" src="https://github.com/user-attachments/assets/eed9d893-dfef-49a6-b3d5-f4821cef7740" />
<img width="876" height="789" alt="Screenshot 2025-10-04 173510" src="https://github.com/user-attachments/assets/44fafc35-0e51-4c20-8b4e-9a9d05bb9431" />
<img width="798" height="692" alt="Screenshot 2025-10-04 173413" src="https://github.com/user-attachments/assets/c0c63c3d-ac1e-47cd-912f-f70ce9661add" />



---
